#!/usr/bin/env python3

# Copyright (C) 2017, Amazon.com. All Rights Reserved
#
# Basic minimal suite of TF to Inkling tests
#
# Examples
#   Existence test
#     /bin/rm -rf [0-9]* ; ./RunAll --verbose --test 0-1conv0
#   All tests
#     /bin/rm -rf [0-9]* ; ./RunAll --verbose
#

import os, sys, re, shutil, signal, psutil
import argparse
import multiprocessing as mp
import time
import multiprocessing
import test_list
import csv
import subprocess
import json

kPath = os.environ.get('KAENA_PATH')
kePath = os.environ.get('KAENA_EXT_PATH')
iPath = os.environ.get('INKLING_PATH')


class Logger(object):
  def __init__(self, logFile):
    self.default = sys.stdout
    self.log = open(logFile, "w")
  def write(self, msg):
    self.default.write(msg)
    self.log.write(msg)  
  def flush(self):
    self.default.flush()
    self.log.flush()  
sys.stdout = Logger('log-RunAll.txt')
sys.stderr = Logger('log-RunAll.txt')

startedAsStr = "\nINFO: started as  %s" % " ".join(sys.argv)
print(startedAsStr)


if kPath == None or kePath == None or iPath == None or \
    not os.path.isdir(kPath) or not os.path.isdir(kePath) or not os.path.isdir(iPath):
  print("ERROR: make sure KAENA_PATH, KAENA_EXT_PATH, and INKLING_PATH environment is set");
  exit(1)

defaultParallel = multiprocessing.cpu_count()

parser = argparse.ArgumentParser()
parser.add_argument('--level', help='Run tests upto this level, default 7. This defines the base set of tests', type=int, default=7)
parser.add_argument('--select', help='Select a specific tests: waived_only, not_waived", default any. This reduces test set from defined by --level', default="any")
parser.add_argument('--test', help='Run specific tests (list). This overrides --level, --select', nargs='+', default=[])
parser.add_argument('--test_re', help='Similar to --test but select by regexp instead of test name; the --test and --test_re are cumulative", default []', nargs='+', default=[])
parser.add_argument('--filter', help='Like --select, but it is applied after --test, --test_re', default="any")
parser.add_argument('--verbose', help='Verbose output', action='store_true', default=False)
parser.add_argument('--show_only', help='Print list of selected tests and exit', action='store_true', default=False)
parser.add_argument('--report_only', help='Print QoR report for the logs in the current directory', action='store_true', default=False)
parser.add_argument('--parallel', help='Run concurrently, default is number of cores', type=int, default=defaultParallel)
parser.add_argument('--max_load', help='Limit number of jobs if  1-minute load exceeds max_load, default is number of cores', type=int, default=defaultParallel)
parser.add_argument('--parallel_streams_for_wave', help='run execution engines in parallel', action='store_true', default=True)
parser.add_argument('--serial_streams_for_wave', help='run execution engines in series', action='store_true', default=False)
parser.add_argument('--timeout', help='Timeout for each test, default 17000 seconds', type=int, default=17000)
parser.add_argument('--inkling_debugflags', help='Pass some arguments to sim, optional', nargs='+', default=[])
parser.add_argument('--small_first', help='Start N small tests before next large one, default 4', type=int, default=4)
parser.add_argument('--no_gpu', help='wave tests that require a GPU', action='store_true', default=False)
parser.add_argument('--force_qemu', help='Apply additional --filer and various customization for Qemu flow, e.g., wave-qemu_inkling instead by auto modifying --scheduler wave.*  to  --scheduler qemu_wave.*; tests with \"fp32\", \"waveopt\", and \"host\" are filtered out.', action='store_true', default=False)
parser.add_argument('--sealife', help='Use sealife compiler instead of kcc', action='store_true', default=False)
parser.add_argument('--waive', help='Additional test to waive', nargs='+', default=[])
parser.add_argument('--cached_kelf', help='Instead of compiling copy test dir from here/test_name and run inference. It can be unix path or s3 url. Also triggers additional comparison with tensors computed by the cached run.', default=None)

args = parser.parse_args()
verbose = args.verbose
level = args.level
parallel = args.parallel
if args.force_qemu and args.parallel == defaultParallel:
  parallel = args.parallel // 2
  print("INFO: using default --parallel %d due to --force_qemu" % parallel)
select = args.select
selectSet = set(["any", "waived_only", "not_waived"])
parallelStreamsForWave = args.parallel_streams_for_wave and not args.serial_streams_for_wave
inklingArgs = " ".join(args.inkling_debugflags)
no_gpu = args.no_gpu

if not select in selectSet:
  print("\nERROR: --select must be one of " + str(selectSet))
  sys.exit(1)
if not args.filter in selectSet:
  print("\nERROR: --filter must be one of " + str(selectSet))
  sys.exit(1)

if verbose:
  print("\nINFO: started as  ", " ".join(sys.argv))


def getLevel(testName):
  return int(testName[0])

def calcIsWaived(testName, testWaiver):
  # Linear search for now is ok
  for regexp,replacementStatus in testWaiver:
    if re.search(regexp, testName):
      return True
  
  return False

# Return True if the cloing was sucessful
def cloneTest(testConfigMap, srcTest, dstTest, fieldIdx, origStr, newStr):
  if not srcTest  in testConfigMap:
    return False
  if not origStr in testConfigMap[srcTest][fieldIdx]:
    return False
  testConfigMap[dstTest] = testConfigMap[srcTest].copy()
  testConfigMap[dstTest][fieldIdx] = re.sub(r'--scheduler wave', "--scheduler qemu_wave", testConfigMap[srcTest][fieldIdx])
  if testConfigMap[dstTest][fieldIdx] == testConfigMap[srcTest][fieldIdx]:
    return False
  print("INFO: cloned test  %s  as  %s" % (srcTest, dstTest))
  return True

def selectTests(testConfigMap, testWaiver, arglevel, argTest,
                argTestRe, argSelect, argFilter, forceQemu):
  testList = []
  # Pre-select by level and the select method
  if len(argTest) == 0 and len(argTestRe) == 0:
    for testName in sorted(testConfigMap):
      isWaived = calcIsWaived(testName, testWaiver)
      if getLevel(testName) <= level:
        if argSelect == "any" or (isWaived and argSelect == "waived_only") or ((not isWaived) and argSelect == "not_waived"):
          testList.append(testName)
  else:
    # Check that all --test exist
    if len(argTest) > 0:
      wrongTests = []

      # Auto-generate qemu versions of existing tests
      for t in argTest:
        if 'qemu' in t and not t in testConfigMap:
          baseTest = t.replace('_qemu', '')
          nnArgsIdx = 3
          if not cloneTest(testConfigMap, baseTest, t, nnArgsIdx, '--scheduler wave', "--scheduler qemu_wave"):
            wrongTests.append(t)
      
      for t in argTest:
        if not t in testConfigMap:
          wrongTests.append(t)
      if len(wrongTests) > 0:
        print("ERROR: the --test %s   do not exist" % str(wrongTests))
        sys.exit(1)
      testList = argTest
    # Add--test_re
    if len(argTestRe) > 0:
      for testName in sorted(testConfigMap):
        for regexp in argTestRe:
          if re.search(regexp, testName):
            testList.append(testName)
  # Filter by the --filter method
  testListFiltered = []
  for testName in testList:
    isWaived = calcIsWaived(testName, testWaiver)
    if argFilter == "any" or (isWaived and argFilter == "waived_only") or ((not isWaived) and argFilter == "not_waived"):
      testListFiltered.append(testName)
  # Apply custom filter
  if forceQemu:
    testsPreCustom = testListFiltered
    testListFiltered = []
    for testName in testsPreCustom:
      isWaived = calcIsWaived(testName, testWaiver)
      if not re.search(r'waveopt', testName) and not re.search(r'host', testName) and not re.search(r'fp32', testName):
        testListFiltered.append(testName)
  # Remove duplicates
  testListFinal = sorted(list(set(testListFiltered)))
  return testListFinal


def runCmd(cmd):
  ret = os.system(cmd)
  return(ret)

###############################################################################
# QoR results for one tests
###############################################################################
class QoR:
  @staticmethod
  def traceGetCycles(filepath):
    cycles = -1
    elapsedTimeSec = -1
    with open(filepath) as data_file:
      trace = json.load(data_file)
      if len(trace) == 0:
        return  int(cycles), float(elapsedTimeSec)

      min_cycles = trace[0]['tts']
      max_cycles = trace[0]['tts']
      for trace_entry in trace:
        tts = trace_entry['tts']
        min_cycles = min(min_cycles, tts)
        max_cycles = max(max_cycles, tts)
      cycles = max_cycles - min_cycles
    return int(cycles), float(elapsedTimeSec)

  @staticmethod
  def simLogGetCycles(filepath):
    cycles = -1
    elapsedTimeSec = -1
    #print("DEBUG: opening %s" % filepath)
    with open(filepath, 'rb') as fh:
      fh.seek(0, os.SEEK_END)
      fileSize = fh.tell()
      fh.seek(-min(200, fileSize), os.SEEK_END)
      for lineBinary in fh.readlines():
        line = lineBinary.decode('ascii')
        found = re.search('Cycles:\s+(\d+)', line)
        if found:
          cycles = found.group(1)
        found = re.search('ElapsedTimeSec:\s+([\d.]+)', line)
        if found:
          elapsedTimeSec = found.group(1)
    return int(cycles), float(elapsedTimeSec)

  # Returns unpadded and padded op counts
  @staticmethod
  def feLogGetOps(filepath):
    ops = 0
    opsPadded = 0
    with open(filepath, 'r') as fh:
      for line in fh:
        match = re.search('INFO: total opcount is (\d+)', line)
        if match:
          ops += int(match.groups(1)[0])
        match1 = re.search('INFO: total padded opcount is (\d+)', line)
        if match1:
          opsPadded += int(match1.groups(1)[0])
    return ops, opsPadded

  headerFields = ("Test", "Status",
                  "TopsRaw", "OpCountRaw",
                  "TopsEff", "OpCountEff",
                  "SimCycles", "SimTimeSec", "SimCycles/sec",
                  "TotTimeSec", "Description")
  def __init__(self, dirName):
    self.freq = 1e9
    self.testName = dirName
    feLog = self.testName + "/" + "log-fe.txt"
    self.tops = 0
    self.topsPadded = 0
    self.ops = 0
    self.opsPadded = 0
    self.cycles = 0
    self.elapsedTimeSec = -1e-6
    self.cyclesPerSec = 0
    if os.path.isfile(feLog):
      self.ops, self.opsPadded = QoR.feLogGetOps(feLog)
      for subdir, dirs, files in os.walk(dirName):
        for file in files:
          #print("DEBUG: visited file  " + os.path.join(subdir, file))
          filepath = subdir + os.sep + file
          testName = filepath.split("/")[0]
          assert (testName == self.testName)
          if re.match(r'.*trace_notifications.json', file):
            #print("DEBUG: processing file  " + os.path.join(subdir, file))
            sgCycles, sgElapsedTimeSec = QoR.traceGetCycles(filepath)
            self.cycles += sgCycles
            self.elapsedTimeSec += sgElapsedTimeSec
          elif re.match(r'log-exec-sg\d+-(wave|tcc)', file):
            sgCycles, sgElapsedTimeSec = QoR.simLogGetCycles(filepath)
            self.cycles += sgCycles
            self.elapsedTimeSec += sgElapsedTimeSec

    if self.cycles > 0:
      self.tops = 1.0 * self.ops / self.cycles / 1e12 * self.freq
      self.topsPadded = 1.0 * self.opsPadded / self.cycles / 1e12 * self.freq
    if self.elapsedTimeSec > 0:
      self.cyclesPerSec = self.cycles / self.elapsedTimeSec

  @staticmethod
  def printHeader(fh):
    fh.write("%-32s  %-16s  %6s %16s  %6s %16s  %16s  %16s %16s  %10s  %s" %
          QoR.headerFields)
    fh.write("-" * 150)

  def getValues(self, status, testTime, description):
    return (self.testName, status,
           self.tops, self.ops,
           self.topsPadded, self.opsPadded,
           self.cycles, self.elapsedTimeSec, self.cyclesPerSec,
           testTime, description)
  def printValues(self, fh, status, testTime, description):
    fh.write("%-32s  %-16s  %6.3f %16g  %6.3f %16g  %16g  %16.3f %16g  %10.1f  %s" %
             self.getValues(status, testTime, description))
  
  
  class HistoryDatabase(object):
    def __init__(self, csvDir, forceQemu):
      self.data = {} # date -> testName -> property -> value
      qorType = 'default'
      if forceQemu:
        qorType = 'qemu'
        if 'ZEBU_SERVER' in os.environ:
          qorType = 'zebu'
      if os.path.isdir(csvDir):
        for subdir, dirs, files in os.walk(csvDir):
          for f in files:
            csvFile = subdir + '/' + f
            #print(csvFile)
            match = re.search(r'(^|\/)(\d+)(\/%s)?\/qor.csv$' % qorType, csvFile)
            if match:
              # Only for default runs allow the legacy directory (with date only, no type subdir)
              date = match.groups()[1]
              if qorType == 'default' or re.search(r'(^|\/)(\d+)(\/%s)\/qor.csv$' % qorType, csvFile):
                self.add(date, csvFile)
    def add(self, date, csvFile):
      self.data[date] = {}
      with open(csvFile) as fh:
        csvReader = csv.DictReader(fh, delimiter=',')
        for row in csvReader:
          #print('DEBUG row:  ', row)
          test = row['Test']
          self.data[date][test] = row
    def getDates(self):
      return sorted(list(self.data.keys()))
    def getValue(self, date, test, prop):
      val = None
      row = self.data[date].get(test, None)
      if row != None:
        val = row.get(prop, None)
      return val

###############################################################################
# Storage for test name, results
###############################################################################
class Ktest:
  def __init__(self, name, dirName, cmd):
    self.name = name
    self.dir = dirName
    self.cmd = cmd
    self.startTime = time.time()
    self.testTime = -1
    self.status = "UNKNOWN"
  def invertStatus(self):
    if self.status == "PASS":
      self.status = "FAIL"
    elif self.status == "FAIL":
      self.status = "PASS"
  def calcRTStatus(self):
    statusFile = self.dir + "/log-rt.txt"
    self.status_rt = "FAIL"
    if os.path.isfile(statusFile):
      with open(statusFile, 'r') as fh:
        for line in fh.readlines():
          match = re.search('INFO .* : Kaena RT status (.*)', line)
          if match:
            self.status_rt = match.group(1)
  def calcKCCStatus(self):
    statusFile = self.dir + "/log-fe.txt"
    self.status_kcc = "FAIL"
    if os.path.isfile(statusFile):
      with open(statusFile, 'r') as fh:
        for line in fh.readlines():
          match = re.search('INFO .* : Kaena Compiler status (.*)', line)
          if match:
            self.status_kcc = match.group(1)

  # Middle end or other intermediate status
  def calcAltStatus(self):
    statusFile = self.dir + "/log-me.txt"
    self.altStatus = "None"
    if os.path.isfile(statusFile):
      with open(statusFile, 'r') as fh:
        for line in fh.readlines():
          match = re.search('^PASSED$', line)
          if match:
            self.altStatus = "PASS"

  def calcStatus(self):
    self.calcRTStatus()
    self.calcKCCStatus()
    self.calcAltStatus()
    if not self.status == "TIMEOUT":
      self.status = "PASS"
      if (self.status != self.status_kcc or self.status != self.status_rt):
        self.status = "FAIL"
      if self.name == "0-neg":
        self.invertStatus()

  def calcQoR(self):
    self.qor = QoR(self.dir)
  def passed(self):
    return self.status == "PASS"
  def failed(self):
    return self.status == "FAIL"
  def timedout(self):
    return self.status == "TIMEOUT"
  def exceededTimeout(self, timeout):
    #print("DEBUG: checking test  %s  for timeout  %f > %f" % (self.name, time.time() - self.startTime, timeout))
    return time.time() > self.startTime + timeout
  def setStatusTimeout(self):
    self.status = "TIMEOUT"
  
###############################################################################
# Storage for all tests
###############################################################################
class Ktests:
  def __init__(self, testConfigMap, testList, testWaiver, testTimeout, smallFirst):
    self.testConfigMap = testConfigMap
    self.testList = testList
    self.testWaiver = testWaiver
    self.testTimeout = testTimeout
    self.smallFirst = smallFirst
    self.startTime = time.time()
    self.process2test = {}
    self.name2test = {}
    self.processes = []
    self.numRunning = 0
    self.sleepSec = 1
    self.numPass = 0
    self.numWaive = 0
    self.numFail = 0
    self.msg = ""
    self.statusCount = 0
    self.testDescriptionREs = []
    testDesriptionFile = os.path.dirname(os.path.realpath(__file__)) + "/test_description.txt"
    with open(testDesriptionFile, 'r') as fh:
      for line in fh:
        match = re.search('(^[^#\s]+)\s+(\S.*)', line)
        if match:
          self.testDescriptionREs.append(match.groups())

  def getNumTests(self):
    return len(self.testList)
    
  def reportStatusWhileRunning(self):
    numAll = self.getNumTests()
    numRun = self.numRunning
    numRunPct = numRun / numAll * 100
    numPass = self.numPass
    numPassPct = numPass / numAll * 100
    numWaive = self.numWaive
    numWaivePct = numWaive / numAll * 100
    numFail = self.numFail
    numFailPct = numFail / numAll * 100
    numOther = numAll - numPass - numWaive - numFail - numRun
    numOtherPct = numOther / numAll * 100
    if self.statusCount %60 == 0:
      print("\n  #Time    Running    Passed    Waived    Failed     Other    Load")
    if self.msg or self.statusCount %10 == 0:
      print("  %6s  %3d %3.0f%%  %3d %3.0f%%  %3d %3.0f%%  %3d %3.0f%%  %3d %3.0f%%  %6.2f   %s" %
            (int(time.time() - self.startTime),
             numRun, numRunPct,
             numPass, numPassPct,
             numWaive, numWaivePct,
             numFail, numFailPct,
             numOther, numOtherPct,
             os.getloadavg()[0],
             self.msg),
            flush=True
           )
    self.statusCount += 1
    self.msg = ""

  # check for running proceses
  def checkProcesses(self, loadLimitForSleep):
    newProcesses = []
    finishedProcesses = []
    for p in self.processes:
      if p.is_alive():
        newProcesses.append(p)
        t = self.getTestByProcess(p)
        if t.exceededTimeout(self.testTimeout):
          time.sleep(0.01)
          
          # The terminate does not correctly signal to all
          # transitive child processes so signal explicitly
          try:
            proc = psutil.Process(p.pid)
            children = proc.children(recursive=True)
            for process in children:
              #print("DEBUG: terminating child %d" % process.pid)
              process.send_signal(signal.SIGTERM)
          except psutil.NoSuchProcess:
            #print("DEBUg: missing process")
            pass
          
          #os.kill(p.pid, signal.SIGKILL)
          #os.killpg(os.getpgid(p.pid), signal.SIGKILL)
          p.terminate()
          t.setStatusTimeout()
      else:
        p.join()
        finishedProcesses.append(p)
    self.postprocess(finishedProcesses)
    self.processes = newProcesses
    self.numRunning = len(self.processes)
    self.reportStatusWhileRunning()
    if self.numRunning >= loadLimitForSleep or os.getloadavg()[0] >= self.maxLoad:
      #print(".", end='', flush=True)
      time.sleep(self.sleepSec)
    return(finishedProcesses)

  def getTestByProcess(self, process):
    return self.process2test[process]

  def getTestByName(self, testName):
    return self.name2test[testName]

  def postprocessOneTest(self, t):
    t.calcStatus()
    t.calcAltStatus()
    t.calcQoR()
    if t.passed():
      self.numPass += 1
    reportStatus = self.calcWaivedStatus(t.name, t.status)
    if t.failed() or t.timedout():
      if 'WAIVE' in  reportStatus:
        self.numWaive += 1
      else:
        self.numFail += 1
    self.msg += "  %s %s" % (t.name, reportStatus)
    if not t.status == "TIMEOUT":
      t.testTime = time.time() - t.startTime

  def postprocess(self, finishedProcesses):
    for p in finishedProcesses:
      t = self.getTestByProcess(p)
      self.postprocessOneTest(t)
  
  def interleaveFrontBack(self, arr, ratio):
    newArr = []
    srcArr = arr.copy()
    while len(srcArr) > 0:
      for i in range(ratio):
        if len(srcArr) > 0:
          newArr.append(srcArr.pop(0))
      if len(srcArr) > 0:
        newArr.append(srcArr.pop(-1))
    return newArr

  # Show test configration
  def showVerbose(self):
    for testName in self.testList:
      (nnStruct, nnConfig) = self.testConfigMap[testName][0:2]
      print("%-20s  %-12s  %s" % (testName, nnStruct, nnConfig))

  # Run tests
  def run(self, parallel, maxLoad, reportOnly, startSpacing, forceQemu, sealife, cachedKelf):
    self.parallel = parallel
    self.maxLoad = maxLoad
    start_time = time.time()
    self.numRunning = 0
    self.processes = []

    outPrefix = "trivnet_"
    lastStartTime = 0
    for testName in self.interleaveFrontBack(self.testList, self.smallFirst):
      # Add default NN args
      while len(self.testConfigMap[testName]) < 5:
        self.testConfigMap[testName].append("")
      (nnStruct, nnConfig, nnLabel, nnArgs, rtArgs) = self.testConfigMap[testName]
      if verbose:
        print("\n############## %s ##############" % testName)
      if forceQemu:
        # Both wave and wave2
        nnArgs = re.sub(r'--scheduler wave', "--scheduler qemu_wave", nnArgs)
      if (not re.search('--wavegraph_checks', nnArgs)):
        nnArgs += ' --wavegraph_checks structure data-race event-conflict'
      if parallelStreamsForWave and ("--scheduler wave" in nnArgs or "--scheduler qemu_wave" in nnArgs):
        nnArgs += " --parallel_streams" # forward option to compiler
      # default ref omage
      default_image =  "%sref_input.npy" % outPrefix
      if ("trivnet" in nnStruct or "ckpt" in nnStruct) and "--images" not in nnArgs:
          nnArgs += " --images %s " % default_image # default if none..
      if ("trivnet" in nnStruct or "ckpt" in nnStruct) and "--input_files" not in rtArgs:
          rtArgs += " --input_files %s " % default_image # default if none..

      rtArgs += ' --inkling_debugflags "%s"' % inklingArgs # add passed inkling args to rt Args
      mtMultiplier = 32
      ulimitCpuTimeout = self.testTimeout * mtMultiplier
      sealifeOpt = ""
      if sealife:
        sealifeOpt = "SEALIFE=1"
      cmd = 'ulimit -t %d; ulimit -H -t %d; mkdir %s && cd %s &&' % (
            ulimitCpuTimeout, ulimitCpuTimeout, testName, testName)
      makeTarget = nnStruct
      if cachedKelf:
        cachedTestPath = "%s/%s" % (cachedKelf, testName)
        makeTarget = "run_kelf_cached CACHED_KELF=%s" % cachedTestPath
        rtArgs += " --cached_goldens %s/working_dir" % cachedTestPath
      cmd += 'make -f  $KAENA_PATH/test/e2e/Makefile %s %s NN_CONFIG=%s OUT_PREFIX=%s NN_NAME=%s NN_ARGS="%s" RT_ARGS="%s"' % (
             makeTarget, sealifeOpt, nnConfig, outPrefix, nnLabel, nnArgs, rtArgs)
      cmd +=  ' > log-top.txt 2>&1'
      # Remove the old directory
      if not reportOnly:
        if os.path.exists(testName):
          oldDir = "%s-old-%d" % (testName, os.getpid())
          #print("DEBUG: renamed %s to %s and removed it" % (testName, oldDir))
          os.rename(testName, oldDir)
          shutil.rmtree(oldDir)

        while self.numRunning >= self.parallel or (
                os.getloadavg()[0] >= self.maxLoad and self.numRunning > 0):
          self.checkProcesses(self.parallel)
        localStartSpacing = startSpacing
        if 'qemu' in testName:
          # Ensure stacing workaround for qemu boot bug even for non-forces qemu tests
          localStartSpacing = 15
        while time.time() - lastStartTime < localStartSpacing:
          self.checkProcesses(0)

        if verbose:
          print("Executing ", cmd)
        else:
          self.msg += "  %s START" % testName
        p = mp.Process(target=runCmd, args=(cmd,))
        #p.daemon = True
        p.start()
        self.numRunning += 1
        self.processes.append(p)
        t = Ktest(testName, testName, cmd)
        self.process2test[p] = t
        self.name2test[testName] = t
        lastStartTime = time.time()
      else:
        t = Ktest(testName, testName, cmd)
        self.name2test[testName] = t
        self.postprocessOneTest(t)

    if not reportOnly:
      while self.numRunning > 0:
        self.checkProcesses(0)

    end_time = time.time()
    elapsedTimeSec = end_time - start_time
    print("\nDone in %.3f sec" % elapsedTimeSec)
    return elapsedTimeSec

  def getTestDescription(self, testName):
    description = "Missing Description"
    for testPattern,Text in self.testDescriptionREs:
      match = re.search(testPattern, testName)
      if match:
        description = Text
    return description

  def calcWaivedStatus(self, testName, status):
    newStatus = status
    newTmpStatus = None
    for regexp,replacementStatus in self.testWaiver:
      if re.search(regexp, testName):
        newTmpStatus = replacementStatus
    if not newTmpStatus == None:
      if status == "FAIL" or status == "TIMEOUT":
        newStatus = newTmpStatus
      elif status == "PASS":
        newStatus = "%s_%s" % (status, newTmpStatus)
    return newStatus

  def calcNumWaivedTest(self):
    numWaived  = 0
    for testName in self.testList:
      t = self.getTestByName(testName)
      reportStatus = self.calcWaivedStatus(testName, t.status)
      if 'WAIVE' in reportStatus and not 'PASS' in reportStatus:
        numWaived += 1
    return numWaived

  def report_junit_xml(self, xmlFileName):
    try:
      import junit_xml as junit
    except ImportError:
      print("\nCould not import junit_xml and so junit test report will not be generated")
      return

    testCases = []
    for testName in self.testList:
      t = self.getTestByName(testName)
      reportStatus = self.calcWaivedStatus(testName, t.status)
      jTestCase = junit.TestCase(name=testName,classname="RunAllTests.RunAllTests",status=reportStatus,elapsed_sec=t.testTime)
      if reportStatus == "FAIL":
        cmd = "find %s -name '*log*.txt' | xargs tail" % (t.dir)
        result = subprocess.check_output(cmd, shell=True).decode('utf-8')
        jTestCase.add_failure_info(message=reportStatus, output=result)
      if reportStatus == "WAIVE":
        jTestCase.add_skipped_info(message=reportStatus)
      if reportStatus == "TIMEOUT":
        cmd = "find %s -name '*log*.txt' | xargs tail" % (t.dir)
        result = subprocess.check_output(cmd, shell=True).decode('utf-8')
        jTestCase.add_error_info(message=reportStatus,output=result)
      testCases.append(jTestCase)
    tSuite = junit.TestSuite(name="RunAll",test_cases=testCases)
    with open(xmlFileName, "w") as fh:
      try:
        junit.TestSuite.to_file(fh,[tSuite], encoding="utf-8")
      except UnicodeEncodeError:
        print("\n Encoding Error and so junit test report will not be generated")
        return


  def report_wavechecker_status (self, rptFileName):
    def calcWCStatus(file_dir):
      statusFile = file_dir + "/log-fe.txt"
      status_wc = 'FAIL'
      if os.path.isfile(statusFile):
        with open(statusFile, 'r') as fh:
          match = False
          for line in fh.readlines():
            match = re.search('(.*) wave_graph_checker failed,(.*)', line)
            if match:
              break
          status_wc = 'FAIL' if match else 'PASS'
      return status_wc

    wc_fail_list = "\n"
    wc_fail_cnt = 0
    wc_pass_cnt = 0
    wc_pass_waive_cnt = 0
    wc_pass_waive_list = "\n"
    wc_pass_list = "\n"
    for testName in self.testList:
      (nnStruct, nnConfig, nnLabel, nnArgs, rtArgs) =\
        self.testConfigMap[testName]
      if (calcWCStatus("./"+testName) == 'FAIL'):
        wc_fail_list += ("\t\t"+testName+"\n")
        wc_fail_cnt += 1
      else:
        if (re.search('--waive_wavegraph_checks',nnArgs)):
          wc_pass_waive_list += ("\t\t"+testName+"\n")
          wc_pass_waive_cnt += 1
        else:
          wc_pass_cnt += 1
          wc_pass_list += ("\t\t"+testName+"\n")
    with open(rptFileName, "w") as fh:
      strStatus = "FAIL_WAVE-CHECKER %d" % wc_fail_cnt
      strStatus += " PASS_WAIVE_WAVE-CHECKER %d" % wc_pass_waive_cnt
      strStatus += " PASS_WAVE-CHECKER %d" % wc_pass_cnt
      fh.write("DETAILED STATUS: %s\n" % strStatus)
      fh.write("\tFAIL_WAVE-CHECKER")
      fh.write(wc_fail_list)
      fh.write("\tPASS_WAIVE_WAVE-CHECKER")
      fh.write(wc_pass_waive_list)
      fh.write("\tPASS_WAVE-CHECKER")
      fh.write(wc_pass_list)
    print("INFO: wrote wave-checker status into %s" % rptFileName)

  def report(self, outFileName, csvFile, prefixText):
    numAll = self.getNumTests()
    numWaived = self.calcNumWaivedTest()
    numPass = self.numPass + numWaived
    numPassPct = numPass / numAll * 100
    with open(outFileName, "w") as fh:
      fh.write(prefixText)
      summaryText = "\nSUMMARY: PASSRATE  %d  %.3f%%  of  %d  (%d were waived)\n" % (numPass, numPassPct, numAll, numWaived)
      fh.write(summaryText)
      print(summaryText)
    
      status2count = {}
      status2test = {}
      for testName in self.testList:
        t = self.getTestByName(testName)
        reportStatus = self.calcWaivedStatus(testName, t.status)
        count = status2count.get(reportStatus, 0)
        status2count[reportStatus] = count + 1
        if not reportStatus in status2test:
          status2test[reportStatus] = []
        status2test[reportStatus].append(testName)
      strStatus = ""
      for status in sorted(status2count):
        strStatus += "%s %d  " % (status, status2count[status])
      fh.write("DETAILED STATUS: %s\n" % strStatus)

      statusList = sorted(status2test)
      if 'PASS' in statusList:
        statusList.append(statusList.pop(statusList.index('PASS')))
      for status in statusList:
        fh.write("  %s\n" % status)
        for test in sorted(status2test[status]):
          fh.write("    %s\n" % test)
      fh.write("\n\n")

      #  Textual QoR was moved to qor.csv
      #QoR.printHeader(fh)
      #for testName in self.testList:
      #  t = self.getTestByName(testName)
      #  testDescription = self.getTestDescription(testName)
      #  reportStatus = self.calcWaivedStatus(testName, t.status)
      #  t.qor.printValues(fh, reportStatus, t.testTime, testDescription)
    print("INFO: Wrote QoR report into  %s" % outFileName)
    
    # Generate csv
    with open(csvFile, 'w') as csvHandle:
      fieldNames = QoR.headerFields
      rows = []
      for testName in self.testList:
        t = self.getTestByName(testName)
        testDescription = self.getTestDescription(testName)
        reportStatus = self.calcWaivedStatus(testName, t.status)
        rowValues = t.qor.getValues(reportStatus, t.testTime, testDescription)
        row = dict(zip(fieldNames, rowValues))
        rows.append(row)
      writer = csv.DictWriter(csvHandle, fieldnames=fieldNames)
      writer.writeheader()
      writer.writerows(rows)
    print("INFO: Wrote op sequences into " + csvFile)

  def dashboard(self, testRe, outFileName):
    with open(outFileName, "w") as fh:
      fh.write("Test description is in  https://sim.amazon.com/issues/kaena-163\n")
      fh.write("%-20s  %-12s  %-12s\n" % ("Test", "MeStatus", "Status"))
      fh.write("-" * 79 + "\n")
      countAll = 0
      countPass = 0
      for testName in self.testList:
        if re.search(testRe, testName):
          t = self.getTestByName(testName)
          fh.write("%-20s  %-12s  %-12s\n" % (testName, t.altStatus, t.status))
          if t.status == 'PASS':
            countPass += 1
          countAll += 1
      if countAll == 0:
        countAll = 1
      fh.write("-" * 79 + "\n" + "PASSRATE  %d of %d  %.3f%%\n" % (countPass, countAll, 100 * countPass / countAll))
    print("INFO: wrote dashboard status into %s" % outFileName)
      
  def plotTops(self, outFile, minTops, normalizeTo, pctLines, keyTests, padded=False):
    test2tops = {}
    for testName in self.testList:
      t = self.getTestByName(testName)
      if t.status == 'PASS':
        tops = t.qor.tops
        if padded:
          tops = t.qor.topsPadded
        if tops >= minTops or testName in keyTests:
          test2tops[testName] = tops
    labels = sorted(test2tops, key=test2tops.get, reverse=True)
    x = [x for x in range(len(labels))]
    y = [test2tops[t] for t in  labels]
    plt.figure(figsize=(12,8))
    #plt.margins(0.8)
    #plt.subplots_adjust(bottom=0.7)
    plt.xticks(x, labels, rotation='vertical')
    plt.bar(x, y, width=0.5, color = 'blue')
    for p, color in pctLines.items():
      val = p / 100 * normalizeTo
      plt.axhline(y=val, color=color)
      plt.text(-3, val + 0.1, '%g%%' % p, color=color)
    for i,v in enumerate(y):
      color = 'black'
      val = (100 * v / normalizeTo)
      valStr = "%2.0f" % val
      if val < 10:
        valStr = "%.3f" % val
      if labels[i] in keyTests:
        color = 'red'
      plt.text(i-0.3, v+len(valStr)/4, "%s" % valStr, rotation='vertical', color=color)
    plt.xlabel('NN')
    paddedStr = 'Raw'
    if padded:
      paddedStr = "Effective"
    plt.ylabel('Tops%s' % paddedStr)
    plt.title('TPB performance (Tops%s) and %s PE efficiency (%%)' % (paddedStr, paddedStr) )
    plt.tight_layout()
    plt.savefig(outFile)
      
  def plotInf(self, outFile, freq, minInfps, maxInfps, keyTests):
    test2infps = {}
    for testName in self.testList:
      t = self.getTestByName(testName)
      if t.status == 'PASS':
        cycles = t.qor.cycles
        if cycles > 0:
          infPs = freq / cycles
          if infPs >= minInfps and infPs <= maxInfps:
            test2infps[testName] = infPs
    labels = sorted(test2infps, key=test2infps.get, reverse=True)
    x = [x for x in range(len(labels))]
    y = [test2infps[t] for t in  labels]
    plt.figure(figsize=(12,8))
    plt.xticks(x, labels, rotation='vertical')
    plt.bar(x, y, width=0.5, color = 'blue')
    for i,v in enumerate(y):
      color = 'black'
      if labels[i] in keyTests:
        color = 'red'
      plt.text(i-0.1, v+300, "%.0f" % v, rotation='vertical', color=color)
    plt.xlabel('NN')
    plt.ylabel('Inf [1/s]')
    plt.title('TPB inferences per second')
    plt.tight_layout()
    plt.savefig(outFile)
      
  def plotHistory(self, outFile, histDb, keyTests):
    histDb.add('new', 'qor.csv')
    xlabels = histDb.getDates()
    x = [x for x in range(len(xlabels))]
    #print("DEBUG x: ", x)
    #print("DEBUG x: ", xlabels)
    fig, axarr = plt.subplots(1, sharex=True, figsize=(16,8))
    axPeUtil  = axarr
    axPeUtil.set_xticks(x)
    axPeUtil.set_xticklabels(xlabels, rotation=90)
    yLineHandles = []
    
    def tests2style(tests):
      t2s = {}
      b2c = {}
      colors = ['red', 'blue', 'green', 'brown', 'orange', 'purple']
      colors += matplotlib.colors.CSS4_COLORS.keys()
      nextColor = 0
      for t in tests:
        ls = 'solid'
        base = t[2:].replace('-two_banks', '').replace('-fast_dram', '')
        if re.search(r'two_banks', t):
          ls = 'dashed'
        elif re.search(r'fast_dram', t):
          ls = 'dotted'
        c = b2c.get(base, None)
        if c == None:
          c = colors[nextColor]
          nextColor += 1
        b2c[base] = c
        t2s[t] = [ls, c]
      return t2s
    
    sortedTest = sorted(keyTests,key=lambda x: x[2:].replace('fast', 'zzz'))
    t2s = tests2style(sortedTest)
    
    for testName in sortedTest:
      y = []
      for date in xlabels:
        util = None
        status = histDb.getValue(date, testName, 'Status')
        topsEff = histDb.getValue(date, testName, 'TopsEff')
        if status == "PASS":
          if topsEff != None:
            util = 100.0 * float(topsEff) / 16
        y.append(util)
      #print("DEBUG y: ", y)
      cleanX = []
      cleanY = []
      for i in range(len(x)):
        if y[i] != None:
          cleanX.append(x[i])
          cleanY.append(y[i])
      ls, color = t2s[testName]
      yLineHandles.append(axPeUtil.plot(cleanX, cleanY, marker='o', ls=ls, c=color, label=testName)[0])
      # Annotate values
      for xv, yv in zip(x, y):
        if yv != None:
          valLabel = "%.1f" % yv
          axPeUtil.annotate(
              valLabel,
              xy=(xv, yv), xytext=(-20, 20),
              textcoords='offset points', ha='right', va='bottom',
              bbox=dict(boxstyle='round,pad=0.5', fc='lightyellow', alpha=0.5),
              arrowprops=dict(arrowstyle = '->', connectionstyle='arc3,rad=0'))
    axPeUtil.legend(handles=yLineHandles)
    axPeUtil.grid(True)
    axPeUtil.set_xlabel('Date')
    axPeUtil.set_ylabel('PE Utilization [%]')
    axPeUtil.set_ylim(0, 100)
    axPeUtil.set_title('PE utilization historical data')
    #fig.autofmt_xdate()
    plt.tight_layout()
    plt.savefig(outFile)
    # Replot as png since Jenkins does not properly display svg
    plt.savefig(os.path.splitext(outFile)[0] + ".png")
      
 
###############################################################################
# Execute
os.nice(18)
testList = selectTests(test_list.testConfigMap, test_list.testWaiver, args.level,
                       args.test, args.test_re, args.select, args.filter,
                       args.force_qemu)
if args.show_only:
  if args.verbose:
    print("INFO: --show_only --verbose mode: selected tests are\n")
    tests = Ktests(test_list.testConfigMap, testList, test_list.testWaiver, args.timeout, args.small_first)
    tests.showVerbose()
  else:
    print("INFO: --show_only mode: selected tests are\n" + "\n".join(testList))
else:
  if no_gpu:
    test_list.testWaiver += test_list.noGpuTestWaiver
  if args.force_qemu:
    test_list.testWaiver += test_list.qemuTestWaiver
  if args.waive:
    test_list.testWaiver += [ [t, "WAIVE_UI"] for t in args.waive]

  tests = Ktests(test_list.testConfigMap, testList, test_list.testWaiver, args.timeout, args.small_first)
  elapsedTimeSec = tests.run(parallel, args.max_load, args.report_only, 15 if args.force_qemu else 0,
                             args.force_qemu, args.sealife, args.cached_kelf)
  tests.report("qor_report.txt", "qor.csv", "%s\nDone in %.3f sec\n" % (startedAsStr, elapsedTimeSec))
  tests.dashboard('3-rn50-\d+_wave', "sprint9-dashboard.txt")
  
  # Qemu Instruction statistics for DV
  cmd = kPath + "/compiler/util/qemu_instr_stats --logdir . --out_csv qor_instr_stats.csv > log-instr_stats.txt 2>&1"
  if args.verbose:
    print("INFO: executing ", cmd)
  instrStatsRet = os.system(cmd)
  if instrStatsRet:
    print("ERROR: qemu_instr_stats failed, check log-instr_stats.txt")
  
  plotQor = False
  try:
    import matplotlib
    matplotlib.use('Agg')
    import matplotlib.pyplot as plt    
    plotQor = True
  except:
    print("WARNING: matplotlib is not installed, skipped Qor plot")
  if plotQor:
    keyDesigns = ['7-rn50_nne_fp16_wave', '7-rn50_nne_fp16_b4_wave', '8-rn50_nne_fp16_b16_wave', '7-rn50_nne_fp16_wave-two_banks', '7-rn50_nne_fp16_b4_wave-two_banks', '8-rn50_nne_fp16_b16_wave-two_banks']
    keyDesignsHistory = keyDesigns + ['7-rn50_nne_fp16_wave-fast_dram', '7-rn50_nne_fp16_b4_wave-fast_dram', '8-rn50_nne_fp16_b16_wave-fast_dram']
    #keyDesignsHistory = ['7-rn50_nne_fp16_wave']
    tests.plotTops("qor_tops_raw.svg", 0.1, 16, {100 : 'lightgreen', 75 : 'gold', 60 : 'orange'}, keyDesigns)
    tests.plotTops("qor_tops_effective.svg", 0.1, 16, {100 : 'lightgreen', 75 : 'gold', 60 : 'orange'}, keyDesigns, padded=True)
    tests.plotInf("qor_inf.svg", 1e9, 0, 5000, keyDesigns)
    histDb = QoR.HistoryDatabase(kPath + '/qor', args.force_qemu)
    tests.plotHistory("qor_history.svg", histDb, keyDesignsHistory)

  # Slower or new (high-risk) reports and actions
  tests.report_junit_xml("RunAllReport.xml")
  tests.report_wavechecker_status("wave_checker_report.txt")

  if tests.numFail or instrStatsRet:
    exit(-1)
    
    
