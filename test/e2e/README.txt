# Copyright (C) 2017, Amazon.com. All Rights Reserved

Steps to run, and extract TPB instruction streams
-------------------------------------------------
Please see section "Checkout Kaena Code and Run Tests" on the New Hire Onboarding page:
https://share.amazon.com/sites/Tonga/SitePages/New%20Hire%20Onboarding.aspx

Test List
----------

The test_list.py contain a dictionary of test name to test specification. 
Each test specification is an array containing the following fields:
- Harness name (name of harness file without extension; see section below)
- Test configurations
- Test class
- TFFE options
- NN Executor options

The test name itself has some information. It starts with a value which represents 
the test level (test complexity) followed by a dash. The rest should be brief description 
of the test. For example:
- "rn50" means ResNet50
- "nne" means using Neural Network Executor flow (break graph into smaller subgraphs)
- "fp16" is float 16
- "wave" means wavegraph flow
- "two_banks" means double the single-bank DRAM BW of Inkling to imitate more realistic dual-bank scenario.

Test List Filtering
-------------------

The test list is filtered automatically for QEMU (remove FP32 tests). Filtering can also be
controlled by RunAll options. Some commonly used options are:

- test_re: filter by name using regular expression
- test: specific test or list of tests (space separated)
- level: filter by the test level (the first number in test name)

More information can be found in RunAll's help:
$KAENA_PATH/test/e2e/RunAll --help

Subgraphing
-----------

The Front-End can partition a large graph into smaller ones for execution on various simulators/devices.

  --focus_to FOCUS_TO   Filter out all nodes but the fanin of this node. The
                        fanin includes the node itself. Partitioning
                        (subgraphing) would operate on this new filtered graph
                        instead of the original graph.

  --partition PARTITION [PARTITION ...]
                        Partition into subgraphs; use from, from_multi,
                        meauto, multi_tpb, or auto. The from_multi is followed
                        by list of comma-separate cut nodes. Example: Use
                        from_multi a,b,c to cut a subgraph starting from nodes
                        a,b,c down toward the output node; if there are two
                        resulting subgraphs, sg00 would contain the input
                        nodes and nodes up to before a,b,c and sg01 would
                        contain a,b,c down toward the output node. The default
                        is none.

  --executors EXECUTORS [EXECUTORS ...]
                        Specifies executors per subgraph, e.g., tcc 1 2 3
                        (implies rest on host, host 0 4 5), default ""

An example is 9-inceptionv3_wave_dog_sg00_tpb_upto_concat1 in test_list.py. To include the first concat
in the first subgraph, specifies the nodes right after the first concat in from_multi list.

More information can be found in RunAll's help:
$KAENA_PATH/compiler/scripts/tffe --help

Test target
-----------

To run test on QEMU (or emulator if you are in emulator environment), use --force_qemu.

Test Output
------------

For each test in filtered test list, Within the test directory (same name as test name), there are:

- log-top.txt: For each test, RunAll calls make using Makefile. The make output is in log-top.txt. 
Here where you can find the commands to run the test manually (starting with TF, then TFFE)
- log-rt.txt: This is the RunTime log. At the end of the test, this log would contain the final
result comparison (as well as comparison for any other intermediate results)
- sg*: These are the directories for different subgraphs generated by TFFE. The indices are 00 to maximum.
- working_dir: This is the working directory for Inkling/QEMU run. The relevant log files are:
    - log-exec-sg*-<target>.txt: The log for each subgraph, run on assigned executor target, which is 
      one of wave, host, qemu_wave.
    - log-exec-sg_<pre/post>-processor.txt: Log output from the pre/post processor; ex. would be image pre-processing.

Debugging
---------

Many debugging tools are located in $KAENA_PATH/compiler/util. It's convenient to add this to your PATH.

The following command execute RunAll across various repo checkouts, ie. to find when regression broke:
$KAENA_PATH/compiler/util/repo_search --since "Sep 26" --until "Oct 2" --run_cmd '$KAENA_PATH/test/e2e/RunAll --test 0-1conv0_wave 6-rn50_nne_to_act46_wave-repl --force_qemu' --sleep 120 --load 60

To run ME by itself, go into the subgraph directory that has compiler.json file, and run:
$KAENA_PATH/compiler/util/run_mid

To compare ME results against golden results, run:
$KAENA_PATH/compiler/util/compare_midout

To run BE/Inkling (standalone), go into the subgraph directory that has compiler.json and wavegraph.json files, and run: 
$KAENA_PATH/compiler/util/run_be_inkling

To compare Inkling results against golden results, run:
$KAENA_PATH/compiler/util/compare_simout

Profiling
---------

1. Compile inkling with profiling enabled:
    cd Inkling/sim; make clean; make opt

2. Run the test with profile info from Inkling:
    ( setenv SIM_ADD_FLAGS '--debug_flags tpb_exec ' ; RunAll --test 7-rn50_nne_fp16_wave )

3. Display overview profile:
    $KAENA_PATH/compiler/util/tpb_profile --log 7-rn50_nne_fp16_wave/working_dir/log-exec-sg00-wave.txt --long 2e6 --show

4. Open detailed interactive profile debug:
    $KAENA_PATH/compiler/util/tpb_profile --log 7-rn50_nne_fp16_wave/working_dir/log-exec-sg00-wave.txt --tpb 7-rn50_nne_fp16_wave/sg00/*.tpb --verbose --show --cycle_range 1e6 1.1e6

Harness list
------------
  Harnesses are small python scripts that create fully functional neural
  networks (more accurately compute graphs). Typically they are heavily
  parametrizable using a simple text string.

Common:
  trivnet_common.py -> a common file containing common routines (see trivnet_conv1.py)

Single-operator:
  trivnet_act.py -> activation tanh, relu
  trivnet_biasadd.py -> bias add
  trivnet_ap1.py -> average pool
  trivnet_mp1.py -> max pool
  trivnet_conv1.py -> conv2d
  trivnet_matmult1.py

Short operator sequences:
  trivnet_add.py -> bias_add with residual add
  trivnet_conv2.py -> 2 layers of Conv2D
  trivnet_conv_pool.py
  trivnet_conv_pool_conv.py
  trivnet_matmul_add.py
  trivnet_scaleadd.py -> scalar multiply followed by add

Longer patterns
  trivnet_conv_ba.py - conv + bias_add + relu/tanh
  trivnet_conv_ba_add.py -> residual add with resnet-like conv branches
  trivnet_conv_ba_mult.py -> residual multioply with resnet-like conv branches
  trivnet_lin.py - multi layer sequence of conv2d followed by act (tanh or relu)

Full networks (and their slices):
  tf_pb -> bypass harness that just passes an existing  tensorflow freeze
           graph neural network representation directly to Kaena compiler

Obsoleted (same can be done more efficiently by other hanesses)
  trivnet_conv1_padvalid.py

  
