#!/usr/bin/env python3

# Copyright (C) 2018, Amazon.com. All Rights Reserved


description='''
Generates goldens and Kaena input files for a single subgraph kaena kelf model
Implements top level of kelf hierachy (anything above krtd) for a single 
purpose of validating multiple inferences on Tonga
SIM kaena-1074, Story kaena-1072
'''

epilog = '''

  Example for resnet50 float16 batch 1 no replication, single SG NN

    $KAENA_PATH/test/e2e/RunAll --test 7-rn50_nosm_fp16_wave-no_repl

    mkdir dir1; cp dog.jpg dir1/img01.jpg; cp cat.jpg dir1/img02.jpg; 

    $KAENA_PATH/runtime/util/runtime_tf_dir --image_dir dir1 --tfpb 7-rn50_nosm_fp16_wave-no_repl/tf.pb --nn_type rn50fp16 --input_map input_1:0=img%d.jpg --output_map fc1000/BiasAdd:0=gold-%d.npy  --num_images 10 --batch 1 --tonga_in_dir tonga_in --tonga_gold_dir tonga_gold  
    
    # Run tonga inference using krtd on  tonga_in/000-prep_tonga.npy and write to img000.bin
    
    $KAENA_PATH/compiler/util/npy_diff_files --gold tonga_gold/gold-000_tonga.npy --new img000.bin


  Example for resnet50 float16 batch 16 replication

    $KAENA_PATH/test/e2e/RunAll --test 8-rn50_nne_fp16_b16_wave

    mkdir dir1; cp dog.jpg dir1/img01.jpg; cp cat.jpg dir1/img02.jpg; 

    $KAENA_PATH/runtime/util/runtime_tf_dir --image_dir dir1 --tfpb 8-rn50_nne_fp16_b16_wave/tf.pb --nn_type rn50fp16repl --input_map input_1:0=img%d.jpg --output_map fc1000/BiasAdd:0=gold-%d.npy  --num_images 32 --batch 16 --tonga_in_dir tonga_in --tonga_gold_dir tonga_gold  
    
    # Run tonga inference using krtd on  tonga_in/000-prep_tonga.npy and write to img000.bin
    
    $KAENA_PATH/compiler/util/npy_diff_files --gold tonga_gold/gold-000_tonga.npy --new img000.bin

'''



import argparse
import os, sys, re
import numpy as np
import random
from tensorflow.python.platform import gfile
from tensorflow.core.framework import graph_pb2
from tensorflow.python.saved_model import tag_constants
import tensorflow as tf

print("\nINFO: started as  ", " ".join(sys.argv), flush=True)

kPath = os.environ.get('KAENA_PATH')
kePath = os.environ.get('KAENA_EXT_PATH')
sys.path.insert(0, kPath + "/compiler")
import numpy as np
from tffe.NpTransforms import NpTrans as npt

parser = argparse.ArgumentParser(description=description, epilog=epilog,
                                 formatter_class=argparse.RawTextHelpFormatter)
parser.add_argument('--tfpb', help='TensorFlow freeze graph file', default="f.pb")
parser.add_argument('--image_dir', help='Directory where to load input images from',
                    default=None)
parser.add_argument('--nn_type', help='Neural network type to select the right preprocessor, default rn50fp16, other rn50fp16repl',
                    default='rn50fp16')
parser.add_argument('--input_map', help='Tensor name to file name map, %%%%d is image id, example '
                    'input1:0=img%%%%d.jpg input2:0=state%%%%d.npy',
                    default=[], nargs='+')
parser.add_argument('--output_map', help='For output tensors and files, same syntax as --input',
                    default=[], nargs='+')
parser.add_argument('--tonga_in_dir', help='Output directory for inputs to tonga kelf, default is cwd',
                    default='.')
parser.add_argument('--tonga_gold_dir', help='Output directory for expected outputs of kelf inference in tonga format, default is cwd',
                    default='.')
parser.add_argument('--num_images', help='Number of images to process. Eg. 400 images with batch 4 means prepare ginputs and golden for 100 inferences, default is 100 ',
                    default=100, type=int)
parser.add_argument('--image_select_seed', help='Seed for the random number generator that selects which image from --image_dir are used, default is 7',
                    default=7, type=int)
parser.add_argument('--batch', help='Batch images for the inference, must match the compiled kelf, default is 1',
                    default=1, type=int)

args = parser.parse_args()
assert len(args.input_map) > 0
assert len(args.output_map) > 0

tfpbFile = args.tfpb
if not os.path.exists(tfpbFile):
  raise("ERROR: missing --tfpb " + tfpbFile)


for d in [args.tonga_in_dir, args.tonga_gold_dir]:
  if not os.path.isdir(d):
    os.mkdir(d)
    assert os.path.isdir(d)


class RuntimeTf:
  
  def __init__(self):
    self.tfg = None
  
  def load(self, tfpbFile):
    self.tfpbFile = tfpbFile
    self.sess = None

    config = tf.ConfigProto()
    config.gpu_options.allow_growth = True
    config.gpu_options.per_process_gpu_memory_fraction = 0.08

    if os.path.isdir(self.tfpbFile):
      # Load model checkpoint
      graph = tf.Graph()
      with graph.as_default():
        # Grow GPU memory as needed at the cost of fragmentation.
        self.sess = tf.Session(graph=graph, config=config)
        tf.saved_model.loader.load( self.sess, [tag_constants.SERVING], self.tfpbFile)
    else:
      self.tfg = graph_pb2.GraphDef()
      with gfile.FastGFile(tfpbFile,'rb') as f:
        self.tfg.ParseFromString(f.read())
      self.sess = tf.Session(config=config)
      with self.sess.as_default():
        tf.import_graph_def(self.tfg, name="")

  def infer(self, inputMap, outputMap):
    with self.sess.as_default():
      graph = self.sess.graph
      
      # Inject input tensors
      feedDict = {}
      for tensorName in inputMap:
        tensorFile = inputMap[tensorName]
        inputTensor = graph.get_tensor_by_name(tensorName)
        inputValue = np.load(tensorFile)

        # Check whether the input is bfloat16, convert if needed
        if inputValue.dtype == '|V2':
          inputValue = np.frombuffer(inputValue.tobytes(), dtype=tf.bfloat16.as_numpy_dtype).reshape(inputValue.shape)

        feedDict[inputTensor] = inputValue
      
      # Collect results
      outputVars = []
      var2file = {}
      for tensorName in outputMap:
        outputVars.append(tensorName)
      tfResults = self.sess.run(outputVars, feed_dict=feedDict)
      for (var, nd) in zip(outputVars, tfResults):
        if nd.size > 0:
          outputFile = outputMap[var]
          np.save(outputFile, np.ascontiguousarray(nd))
          print("\nINFO: wrote tensor %s into %s" %
                (var, outputFile), flush=True)

# maps tensor name to a file pattern
class TensorFileMap:
  def __init__(self, tensorMapStr):
    self.tensorName, self.filePattern = tensorMapStr.split('=')
    self.fileRe = re.compile(self.filePattern.replace('%d', '(\d+)'))

class Fmaps:

  def __init__(self, imageDir, nnType, inputMaps, outputMaps, runtime):
    self.imageDir = imageDir
    self.nnType = nnType
    self.inputMaps = [TensorFileMap(im) for im in inputMaps]
    self.outputMaps = [TensorFileMap(om) for om in outputMaps]
    self.runtime = runtime
    self.inputFiles = {}
    self.tfInputFiles = {}
    self.outputFiles = {}
    self.batches = []
    # Identify all input files
    for f in os.listdir(self.imageDir):
      for im in self.inputMaps:
        match = re.search(im.fileRe, f)
        if match:
          imgIdStr = match.group(1)
          imgId = int(imgIdStr)
          if self.inputFiles.get(imgId) == None:
            self.inputFiles[imgId] = {}
          self.inputFiles[imgId][im.tensorName] = f
          print('INFO: found file ', f, imgId, im.tensorName)

  def selectImages(self, numImages, batchSize, seed):
    random.seed(seed)
    numAvail = len(self.inputFiles)
    print('INFO: found %d available images' % numAvail)
    numBatches = numImages // batchSize
    assert len(self.inputMaps) == 1   # This part of code does not support multi-input NNs
    im = self.inputMaps[0]
    tensorName = im.tensorName
    for b in range(numBatches):
      images = []
      imgIds = []
      for i in range(batchSize):
        imgId = random.randint(0, numAvail)
        while self.inputFiles.get(imgId) == None:
          imgId = random.randint(0, numAvail)
        images.append(self.inputFiles[imgId][tensorName])
        imgIds.append(imgId)
      self.batches.append(images)
      print('INFO: batch %d uses images %s' % (b, " ".join([str(i) for i in imgIds])))
      

  # Network specific pre/postprocessors
  def preprocess(self, tongaInDir, tongaGoldDir):
    
    # Define names of output files
    for infId in range(len(self.batches)):
      for om in self.outputMaps:
        pat = om.filePattern.replace('%d', '%00d')
        if self.outputFiles.get(infId) == None:
          self.outputFiles[infId] = {}
        self.outputFiles[infId][om.tensorName] = tongaGoldDir + '/' + pat % infId
        print('INFO: mapped output ', infId, om.tensorName, self.outputFiles[infId][om.tensorName])

    if self.nnType == 'rn50fp16' or self.nnType == 'rn50fp16repl':
      assert len(self.inputMaps) == 1   # This part of code does not support multi-input NNs
      im = self.inputMaps[0]
      tensorName = im.tensorName
      om = self.outputMaps[0]
      outTensorName = om.tensorName
      for infId in range(len(self.batches)):
        rnPre = os.path.join(kPath, "compiler/util/res50_preprocessor.py --data-type fp16")
        images = self.batches[infId]
        foutBase = '%03d' % infId
        fout = foutBase + '-prep_tf.npy'
        rnPre += '  --inputs ' + " ".join(["%s/%s" % (self.imageDir, fin) for fin in images])
        rnPre += '  --output ' + fout
        print('INFO: ', rnPre)
        os.system(rnPre)
        self.tfInputFiles[infId]= {tensorName : fout}

        # Reformat the input fmap layout for Tonga runtime
        foutTonga = foutBase + '-prep_tonga.npy'
        absFoutTonga = tongaInDir + '/' + foutTonga
        npt.formatNpyFileAs(fout, 'NHWC', 'NCHW', outFile=absFoutTonga)
        
        # Padd split data for replication
        if self.nnType == 'rn50fp16repl':
          cmd = 'mv %s trivnet_input_1:0_NCHW.npy; ' % absFoutTonga
          cmd += kPath + '/compiler/util/padsplit_npy_for_repl.py --input_file trivnet_input_1:0_NCHW.npy --format NCHW --stride 2 --padding="[ [0,0], [0,0], [2,3], [2,3] ]"; '
          cmd += 'mv trivnet_input_1:0_NCHW_padsplit_stride2_n2_s3_w2_e3.npy ' + absFoutTonga
          print('INFO: executing ', cmd)
          os.system(cmd)
          
    else:
      raise ValueError('ERROR: unrecognized --nn_type ' + self.nnType)

  def postprocess(self, batchSize):

    if self.nnType == 'rn50fp16' or self.nnType == 'rn50fp16repl':
      for infId in sorted(self.outputFiles):
        tensorName = list(self.outputFiles[infId].keys())[0]
        foutTf = self.outputFiles[infId][tensorName]
        assert foutTf.endswith('.npy')
        foutTonga = foutTf.replace('.npy', '_tonga.npy')
        npt.formatNpyFileAs(foutTf, 'NHWC', 'NCHW', outFile=foutTonga, srcShape=[batchSize,1,1,1000])
    else:
      raise ValueError('ERROR: unrecognized --nn_type ' + self.nnType)

  def infer(self):
    for infId in range(len(self.batches)):
      self.runtime.infer(self.tfInputFiles[infId], self.outputFiles[infId])


runtime = RuntimeTf()
runtime.load(tfpbFile)
fmaps = Fmaps(args.image_dir, args.nn_type, args.input_map, args.output_map, runtime)
fmaps.selectImages(args.num_images, args.batch, args.image_select_seed)
fmaps.preprocess(args.tonga_in_dir, args.tonga_gold_dir)
fmaps.infer()
fmaps.postprocess(args.batch)
